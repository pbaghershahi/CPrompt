{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fe62f6-2bc5-4d57-932f-e7c46a4b1071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  7 18:05:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090         Off| 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   21C    P8               26W / 350W|      0MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f4b148-c4a1-414e-84b1-5e350519f4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.0+cu117\n",
      "Uninstalling torch-2.0.0+cu117:\n",
      "  Successfully uninstalled torch-2.0.0+cu117\n",
      "Found existing installation: torchvision 0.15.1+cu117\n",
      "Uninstalling torchvision-0.15.1+cu117:\n",
      "  Successfully uninstalled torchvision-0.15.1+cu117\n",
      "Found existing installation: torchaudio 2.0.1+cu117\n",
      "Uninstalling torchaudio-2.0.1+cu117:\n",
      "  Successfully uninstalled torchaudio-2.0.1+cu117\n",
      "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pyg_lib as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.1.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp311-cp311-linux_x86_64.whl (2200.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.16.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.1.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.1.0) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch==2.1.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.1.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.1.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.1.0) (2023.9.0)\n",
      "Collecting triton==2.1.0 (from torch==2.1.0)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision==0.16.0) (1.24.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from torchvision==0.16.0) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision==0.16.0) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.1.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->torchvision==0.16.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->torchvision==0.16.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->torchvision==0.16.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->torchvision==0.16.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.1.0) (1.3.0)\n",
      "Installing collected packages: triton, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.0+cu121 torchaudio-2.1.0+cu121 torchvision-0.16.0+cu121 triton-2.1.0\n",
      "torch-2.1.0+cu121.html\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
      "Collecting pyg-lib==0.3.1\n",
      "  Using cached https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.3.1%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (2.4 MB)\n",
      "Installing collected packages: pyg-lib\n",
      "Successfully installed pyg-lib-0.3.1+pt21cu121\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from torch-sparse) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.11/site-packages (from scipy->torch-sparse) (1.24.3)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from torch-cluster) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.11/site-packages (from scipy->torch-cluster) (1.24.3)\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.6.3+pt21cu121\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
      "Collecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (935 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m936.0/936.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
      "Successfully installed torch-spline-conv-1.2.2+pt21cu121\n",
      "Collecting torch-geometric\n",
      "  Obtaining dependency information for torch-geometric from https://files.pythonhosted.org/packages/65/4e/6f9a75548a93fedcd4514ae2de9bee1e91bade6b73252b4da32f0e42ac52/torch_geometric-2.4.0-py3-none-any.whl.metadata\n",
      "  Using cached torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (1.11.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.11/site-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->torch-geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
      "Using cached torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.4.0\n",
      "Collecting osmnx\n",
      "  Obtaining dependency information for osmnx from https://files.pythonhosted.org/packages/5e/ab/2e29d26454a8a9bdedb7a9be8920c6a9b88e5e6caae15cbba0d50a134697/osmnx-1.9.1-py3-none-any.whl.metadata\n",
      "  Using cached osmnx-1.9.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting geopandas>=0.12 (from osmnx)\n",
      "  Obtaining dependency information for geopandas>=0.12 from https://files.pythonhosted.org/packages/90/37/08e416c9915dcf7d53deb0fbdb702266902c584617dfa6e6c84fb2fc6ee3/geopandas-0.14.3-py3-none-any.whl.metadata\n",
      "  Using cached geopandas-0.14.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.11/site-packages (from osmnx) (3.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from osmnx) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.1 in /opt/conda/lib/python3.11/site-packages (from osmnx) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.27 in /opt/conda/lib/python3.11/site-packages (from osmnx) (2.31.0)\n",
      "Collecting shapely>=2.0 (from osmnx)\n",
      "  Obtaining dependency information for shapely>=2.0 from https://files.pythonhosted.org/packages/8c/47/05c8bb8322861113e72b903aebaaa4678ae6e44c886c189ad8fe297f2008/shapely-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached shapely-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting fiona>=1.8.21 (from geopandas>=0.12->osmnx)\n",
      "  Obtaining dependency information for fiona>=1.8.21 from https://files.pythonhosted.org/packages/07/ea/6674320c62a688bc1dc14201dfb7d4aeaea0939a1e733b85bae39e177325/fiona-1.9.5-cp311-cp311-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached fiona-1.9.5-cp311-cp311-manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from geopandas>=0.12->osmnx) (23.1)\n",
      "Collecting pyproj>=3.3.0 (from geopandas>=0.12->osmnx)\n",
      "  Obtaining dependency information for pyproj>=3.3.0 from https://files.pythonhosted.org/packages/64/90/dfe5c00de1ca4dbb82606e79790659d4ed7f0ed8d372bccb3baca2a5abe0/pyproj-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pyproj-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1->osmnx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1->osmnx) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1->osmnx) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.27->osmnx) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12->osmnx) (23.1.0)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12->osmnx) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12->osmnx) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12->osmnx) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12->osmnx) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas>=0.12->osmnx) (68.1.2)\n",
      "Using cached osmnx-1.9.1-py3-none-any.whl (104 kB)\n",
      "Using cached geopandas-0.14.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached shapely-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached fiona-1.9.5-cp311-cp311-manylinux2014_x86_64.whl (15.7 MB)\n",
      "Using cached pyproj-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Installing collected packages: shapely, pyproj, fiona, geopandas, osmnx\n",
      "Successfully installed fiona-1.9.5 geopandas-0.14.3 osmnx-1.9.1 pyproj-3.6.1 shapely-2.0.2\n",
      "pyg_lib version:  0.3.1+pt21cu121\n",
      "Installed requirements\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip uninstall -y torch\n",
    "!pip uninstall -y pyg_lib\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "import torch\n",
    "pytorch_version = f'torch-{torch.__version__}.html'\n",
    "print(pytorch_version)\n",
    "!pip install pyg-lib==0.3.1 -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
    "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
    "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
    "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
    "!pip install torch-geometric\n",
    "!pip install osmnx\n",
    "import pyg_lib\n",
    "print(\"pyg_lib version: \", pyg_lib.__version__)\n",
    "!python -c \"from IPython.display import clear_output; clear_output(); print('Installed requirements')\"\n",
    "# %cd  /home/jovyan/CPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1245d65-17c5-4d4b-8e90-1e3c6b770270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/CPrompt\n"
     ]
    }
   ],
   "source": [
    "%cd  /home/jovyan/CPrompt\n",
    "import torch, random, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torchvision.transforms.functional import normalize\n",
    "from torch_geometric.utils import augmentation, to_dense_adj\n",
    "from torch_geometric.nn import GAT, GATConv, GCNConv\n",
    "from torch_geometric.datasets import QM9, TUDataset\n",
    "from torch_geometric.loader import DataLoader, DenseDataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from utils import *\n",
    "from model import GCN, LinkPredictionPrompt\n",
    "from copy import deepcopy\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a47b59-722d-4976-ade9-586944d10403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_loader = NeighborLoader(\n",
    "    dataset[0],\n",
    "    input_nodes=torch.arange(dataset.x.size(0)),\n",
    "    num_neighbors=[-1]*2,\n",
    "    batch_size=1,\n",
    "    replace=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "for i, batch in enumerate(t_loader):\n",
    "    print(i, batch.input_id)\n",
    "# t_batch = next(iter(t_loader))\n",
    "# print(dataset[0].y[0], dataset[0].y[t_batch.n_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8091db8-ae65-4e05-b376-94448dc81a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 0, 5, 6, 7, 8, 9],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch.edge_index[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7013f7e0-3849-4ead-868d-976fb6dfd0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  507, 6551, 8210, 9745,   31,   40,  182,  430,  468])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch.n_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77fa6be1-b94c-42be-b8c3-07427538c19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch.input_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f398a77-4762-480d-b066-819ce5fd1611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 17728, 236356, 297090, 350263,      0,    934,   1367,   6694,  14827,\n",
       "         16368])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch.e_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c01b349-add5-4b36-a542-938f09b6de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 507, 6551, 8210, 9745,    0,   31,   40,  182,  430,  468],\n",
       "        [   0,    0,    0,    0,  507,  507,  507,  507,  507,  507]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_index[:, t_batch.e_id[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "711c26d0-ea6f-48c4-a55b-3a999cf92ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13752])\n",
      "13471\n",
      "13752\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].y.size())\n",
    "print(len(node_ds.all_nids))\n",
    "print(len(t_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7b6819c-043e-4122-bf03-ee09985e5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassification(Dataset):\n",
    "    def __init__(self, dataset, n_hopes=2, train_per=0.85, test_per=0.15):\n",
    "        self._data = dataset[0]\n",
    "        if train_per + test_per != 1.0:\n",
    "            valid_per = 1 - (train_per + test_per)\n",
    "        else:\n",
    "            valid_per = 0.0\n",
    "        print(\"Toral num nodes: \", dataset.x.size(0))\n",
    "        loader = NeighborLoader(\n",
    "            self._data,\n",
    "            input_nodes=torch.arange(dataset.x.size(0)),\n",
    "            num_neighbors=[-1]*n_hopes,\n",
    "            batch_size=1,\n",
    "            replace=False,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        print(\"Neighborhood Loader Created\")\n",
    "        self.all_edges = []\n",
    "        self.all_nids = []\n",
    "        self.r_nodes = []\n",
    "        for i, batch in enumerate(loader):\n",
    "            if batch.n_id.size(0) > 1:\n",
    "                print(f\"Batch num: {i}/{len(loader)}\", end='\\r', flush=True)\n",
    "                self.r_nodes.append(batch.input_id)\n",
    "                self.all_nids.append(batch.n_id)\n",
    "                self.all_edges.append(batch.edge_index)\n",
    "        self.r_nodes = torch.tensor(self.r_nodes)\n",
    "        self.n_nodes = len(self.all_nids)\n",
    "        self.n_feats = dataset.x.size(1)\n",
    "        self.n_classes = dataset.num_classes\n",
    "        self.train_idx = int(self.n_nodes * train_per)\n",
    "        self.n_train = self.train_idx\n",
    "        self.n_valid = int(self.n_nodes * valid_per)\n",
    "        self.test_idx = self.train_idx + int(self.n_nodes * valid_per)\n",
    "        self.n_test = self.n_nodes - self.test_idx\n",
    "        self.labels = self._data.y\n",
    "\n",
    "    def _shuffle(self,):\n",
    "        perm = torch.randperm(self.train_idx)\n",
    "        self.all_nids[:self.train_idx] = [self.all_nids[i] for i in perm]\n",
    "        self.all_edges[:self.train_idx] = [self.all_edges[i] for i in perm]\n",
    "        self.r_nodes[:self.train_idx] = self.r_nodes[perm]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_nodes\n",
    "\n",
    "    def __getitem__(self, indices):\n",
    "        if isinstance(indices, int):\n",
    "            indices = [indices]\n",
    "        elif isinstance(indices, slice):\n",
    "            indices = [i for i in range(*indices.indices(len(self)))]\n",
    "        else:\n",
    "            raise TypeError(\"Invalid index type. Must be int, slice, or list.\")\n",
    "        all_graphs = []\n",
    "        for idx in indices:\n",
    "            x = self._data.x[self.all_nids[idx]]\n",
    "            y = self._data.y[self.r_nodes[idx]]\n",
    "            edges = self.all_edges[idx]\n",
    "            all_graphs.append(Data(x=x, edge_index=edges, y=y))\n",
    "        return all_graphs, self._data.y[self.r_nodes[indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fb77d64-6cfa-421f-b119-414d5e349fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toral num nodes:  13752\n",
      "Neighborhood Loader Created\n",
      "Batch num: 13751/13752\r"
     ]
    }
   ],
   "source": [
    "dataset = Amazon(\n",
    "    root='data/Amazon',\n",
    "    name='Computers'\n",
    "    )\n",
    "node_ds = NodeClassification(dataset, n_hopes=2, train_per=0.85, test_per=0.15)\n",
    "node_ds._shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcb6d9fe-0d7e-4818-8f89-4b4ea918e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t main.py   old_main.py\t old_prompt.py\tpretrain.py  README.md\n",
      "installation.sh  model.py  old_model.py  old_utils.py\t__pycache__  utils.py\n"
     ]
    }
   ],
   "source": [
    "!cp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1309117-afb8-4984-bafe-bb5572e436d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_sparse(spmat):\n",
    "    indices = spmat.nonzero(as_tuple=False)\n",
    "    spmat = torch.sparse_coo_tensor(\n",
    "        indices.T,\n",
    "        spmat[indices[:, 0], indices[:, 1]],\n",
    "        size=spmat.size(),\n",
    "        requires_grad=True\n",
    "        )\n",
    "    return spmat\n",
    "\n",
    "def batch_to_xadj_list(g_batch, device):\n",
    "    x_adj_list = []\n",
    "    for i, g in enumerate(g_batch):\n",
    "        g = g.to(device)\n",
    "        adj_dense = to_dense_adj(g.edge_index, max_num_nodes=g.x.size(0)).squeeze()\n",
    "        deg_mat = adj_dense.sum(dim=1)\n",
    "        deg_mat_inv = torch.max(deg_mat, torch.ones_like(deg_mat)*1e-6).pow(-1)\n",
    "        deg_mat_inv = deg_mat_inv.diag()\n",
    "        adj_dense = deg_mat_inv @ adj_dense\n",
    "        adj_dense.fill_diagonal_(1.)\n",
    "        adj_sparse = dense_to_sparse(adj_dense)\n",
    "        x_adj_list.append((g.x, adj_sparse))\n",
    "    return x_adj_list\n",
    "\n",
    "def test(model, dataset, batch_size, device, epoch=None, visualize=False, colors=None):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    for i in range(dataset.test_idx, dataset.n_nodes, batch_size):\n",
    "        print(f\"Test batch: {i}/{node_ds.test_idx}\", end='\\r')\n",
    "        test_batch, test_labels = dataset[i:min(i+batch_size, dataset.n_nodes)]\n",
    "        x_adj_list = batch_to_xadj_list(test_batch, device)\n",
    "        out, embeds = model(x_adj_list)\n",
    "        if visualize:\n",
    "            visualize_and_save_tsne(\n",
    "                embeds.cpu().detach().numpy(),\n",
    "                colors[test_labels.cpu()] if colors is not None else None,\n",
    "                epoch if epoch is not None else 0)\n",
    "        test_loss += F.cross_entropy(out, test_labels.to(device), reduction=\"sum\")\n",
    "        out = F.softmax(out, dim=1)\n",
    "        pred = out.max(dim=1)[1]\n",
    "        correct += int((pred == test_labels.to(device)).sum())\n",
    "    test_loss /= dataset.n_test\n",
    "    test_acc = correct / dataset.n_test\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c90d267-5436-438c-ba76-0c63c3d9092c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/300, Train Loss: 0.9923, Main Loss: 0.7932, Main ACC: 0.741\n",
      "Epoch: 1/300, Train Loss: 0.6196, Main Loss: 0.6549, Main ACC: 0.787\n",
      "Epoch: 2/300, Train Loss: 0.6400, Main Loss: 0.7300, Main ACC: 0.770\n",
      "Epoch: 3/300, Train Loss: 0.7597, Main Loss: 0.6820, Main ACC: 0.773\n",
      "Epoch: 4/300, Train Loss: 0.6139, Main Loss: 0.5821, Main ACC: 0.809\n",
      "Epoch: 5/300, Train Loss: 0.3591, Main Loss: 0.5804, Main ACC: 0.812\n",
      "Epoch: 6/300, Train Loss: 0.7764, Main Loss: 0.6175, Main ACC: 0.804\n",
      "Train batch: 576/11450\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m     emb_out, _ \u001b[38;5;241m=\u001b[39m model(x_adj_list)\n\u001b[1;32m     32\u001b[0m     loss \u001b[38;5;241m=\u001b[39m obj_fun(emb_out, train_labels\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h_dim = 64\n",
    "n_layers = 2\n",
    "batch_size = 64\n",
    "visualize = False\n",
    "if visualize:\n",
    "    colors = np.array([\n",
    "        \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) \\\n",
    "        for i in range(dataset.y.unique().size(0))])\n",
    "else:\n",
    "    colors = None\n",
    "\n",
    "model = GCN(node_ds.n_feats, h_dim, nclass=node_ds.n_classes, dropout=0.2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# for d in train_loader:\n",
    "#     d.to(device)\n",
    "obj_fun = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "n_epochs = 300\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    node_ds._shuffle()\n",
    "    for i in range(0, node_ds.train_idx, batch_size):\n",
    "    # for i in range(0, 1000, batch_size):\n",
    "        print(f\"Train batch: {i}/{node_ds.train_idx}\", end='\\r')\n",
    "        train_batch, train_labels = node_ds[i:min(i+batch_size, node_ds.train_idx)]\n",
    "        x_adj_list = batch_to_xadj_list(train_batch, device)\n",
    "        optimizer.zero_grad()\n",
    "        emb_out, _ = model(x_adj_list)\n",
    "        loss = obj_fun(emb_out, train_labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        test_loss, test_acc = test(\n",
    "            model, node_ds, 32, device, epoch, visualize, colors)\n",
    "        print(f'Epoch: {epoch}/{n_epochs}, Train Loss: {loss:.4f}, Main Loss: {test_loss:.4f}, Main ACC: {test_acc:.3f}')\n",
    "\n",
    "save_model = True\n",
    "if save_model:\n",
    "    model_dir = './pretrained'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    name = datetime.today().strftime('%Y_%m_%d_%H_%M')\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, os.path.join(model_dir, f'model_{name}.pt')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a8772-4246-44f7-ae9f-b8e6de50e29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
